{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# P.A.C.E\n"
      ],
      "metadata": {
        "id": "rDkprvUIKlPL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project: P.A.C.E - Pythonic AI for Coding and Execution\n",
        "\n",
        "## This project demonstrates how to use NVIDIA's NeMo API to generate Python code from natural language descriptions of coding tasks.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZP8pqBzkL4mD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intalling Required Libraries\n"
      ],
      "metadata": {
        "id": "Vg9aVSWbNkNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!huggingface-cli login\n",
        "# Uncomment the above line to log in to Hugging Face, if needed.\n",
        "\n"
      ],
      "metadata": {
        "id": "A-nnTYf91Yrv",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fabdd276-d38a-4238-9443-aa6446153d2f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: write).\n",
            "The token `code_generation` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `code_generation`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install OpenAI library for API calls to NVIDIA's NeMo services\n",
        "# Uncomment the following line to install the library\n",
        "#!pip install openai"
      ],
      "metadata": {
        "id": "q-XXjbyXz7Dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc1fe5bd-90cc-410f-9e72-04f8e25ae990"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.59.8-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Downloading openai-1.59.8-py3-none-any.whl (455 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.6/455.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.6/345.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 jiter-0.8.2 openai-1.59.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import OpenAI & NVIDIA NeMo client"
      ],
      "metadata": {
        "id": "DmKKWTYdNwxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import OpenAI client for handling API interactions\n",
        "from openai import OpenAI\n",
        "\n",
        "# Initialize the NVIDIA NeMo client\n",
        "# Here, I am using the OpenAI API wrapper to access NVIDIA's integration.\n",
        "# Note: Replace the API key with a valid key. Never expose sensitive keys in public code!\n",
        "client = OpenAI(\n",
        "    base_url=\"https://integrate.api.nvidia.com/v1\",  # NVIDIA NeMo API base URL\n",
        "    api_key=\"YOUR_API_KEY\"  # Replace with your actual API key\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pyeNHL8oPhiu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining function to Generate code from user Prompt"
      ],
      "metadata": {
        "id": "bn5la8uLN-Rk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code(prompt, model=\"nvidia/llama-3.1-nemotron-51b-instruct\", max_tokens=512):\n",
        "    \"\"\"\n",
        "    Generates Python code based on a natural language description (prompt).\n",
        "\n",
        "    Parameters:\n",
        "    - prompt (str): A plain-text description of the programming task.\n",
        "    - model (str): The model to use for code generation.\n",
        "                  Default: \"nvidia/llama-3.1-nemotron-51b-instruct\".\n",
        "    - max_tokens (int): The maximum number of tokens for the generated output.\n",
        "\n",
        "    Returns:\n",
        "    - str: The Python code generated by the AI model.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Calling NVIDIA NeMo API for code generation\n",
        "        # Using chat-completions endpoint for structured interactions\n",
        "        completion = client.chat.completions.create(\n",
        "            model=model,  # The AI model to use\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],  # User-provided prompt\n",
        "            temperature=0.5,  # Controls randomness (lower = deterministic)\n",
        "            top_p=1,         # Cumulative probability for nucleus sampling\n",
        "            max_tokens=max_tokens,  # Limit the output length\n",
        "            stream=False      # Stream=False ensures full output in one response\n",
        "        )\n",
        "\n",
        "        # Return the generated code from the API response\n",
        "        return completion.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        # Handle any errors gracefully\n",
        "        return f\"Error: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "jwS1uzM7PpJH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get user Prompt & Generate code"
      ],
      "metadata": {
        "id": "QozS-K6iOIZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entry point for interactive usage\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    This section runs an interactive script where the user provides a coding task,\n",
        "    and the AI generates the corresponding Python code.\n",
        "    \"\"\"\n",
        "\n",
        "    # Prompt the user for a coding task description\n",
        "    prompt = \"A Python function to \" + input(\"Enter your problem: \")\n",
        "\n",
        "    # Generate code based on the user's description\n",
        "    generated_code = generate_code(prompt)\n",
        "\n",
        "    # Display the original prompt and the generated code\n",
        "    print(\"\\nPrompt:\\n\", prompt, \"\\n\\nGenerated Code:\\n\\n\", generated_code)\n"
      ],
      "metadata": {
        "id": "pjJadXXHPt9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ecb127a-ef60-4963-968e-8e6f2fe903e8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your problem: eliminate even digits from the given number and print the remaining number\n",
            "\n",
            "Prompt:\n",
            " A Python function to eliminate even digits from the given number and print the remaining number \n",
            "\n",
            "Generated Code:\n",
            "\n",
            " **Removing Even Digits from a Number in Python**\n",
            "\n",
            "Here is a simple Python function that takes an integer as input, removes all even digits, and returns the resulting number as an integer.\n",
            "\n",
            "```python\n",
            "def remove_even_digits(num):\n",
            "    \"\"\"\n",
            "    Removes all even digits from the given number.\n",
            "    \n",
            "    Args:\n",
            "        num (int): The input number.\n",
            "    \n",
            "    Returns:\n",
            "        int: The number with all even digits removed.\n",
            "    \"\"\"\n",
            "    # Convert the number to a string to easily iterate over its digits\n",
            "    num_str = str(num)\n",
            "    \n",
            "    # Initialize an empty string to store the remaining digits\n",
            "    remaining_digits = \"\"\n",
            "    \n",
            "    # Iterate over each digit in the number\n",
            "    for digit in num_str:\n",
            "        # Check if the digit is odd\n",
            "        if int(digit) % 2 != 0:\n",
            "            # If the digit is odd, append it to the remaining digits string\n",
            "            remaining_digits += digit\n",
            "    \n",
            "    # If there are no remaining digits, return 0\n",
            "    if not remaining_digits:\n",
            "        return 0\n",
            "    \n",
            "    # Convert the remaining digits string back to an integer and return it\n",
            "    return int(remaining_digits)\n",
            "\n",
            "# Example usage:\n",
            "print(remove_even_digits(123456))  # Output: 135\n",
            "print(remove_even_digits(24680))   # Output: 0\n",
            "print(remove_even_digits(11111))   # Output: 11111\n",
            "```\n",
            "\n",
            "This function works by converting the input number to a string, iterating over each digit, checking if it's odd, and appending it to a new string if it is. Finally, it converts the new string back to an integer and returns it. If there are no odd digits in the input number, the function returns 0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jv6UnRxuC4B-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}